# ğŸ§  model-persistence-rnn

A hands-on implementation of a character-level Recurrent Neural Network (RNN) for text generation, trained to approximate the structure of Limerick poetry. This repository demonstrates model persistence (saving and loading), efficient training using Google Colab, and performance comparison across model variations.

---

## ğŸ“Œ Overview

The project consists of two tasks:

### **Task A â€“ Model Training and Persistence**
- Set up for execution in **Google Colab** with GPU acceleration  
- Dataset loading and preprocessing for character-level modeling  
- RNN architecture implemented using **PyTorch**  
- Model training loop  
- **Model saving and loading** logic using `torch.save` and `torch.load`  

### **Task B â€“ Text Generation with Trained RNNs**
- Functions to **generate limerick-style text** from trained models  
- Use of **temperature scaling** to control output diversity  
- Comparison of outputs from two versions:  
  - `model_v1`: shorter generation  
  - `model_v2`: longer generation with increased temperature  
- Critical reflection on model performance:  
  - Structure partially learned (line breaks, poetic form)  
  - Limitations in rhyme and semantics  

---

## ğŸ—ƒï¸ Directory Structure

model-persistence-rnn/
â”œâ”€â”€ A_RNN.ipynb # Model training, Colab setup, and persistence
â”œâ”€â”€ B_RNN.ipynb # Limerick generation with trained models
â”œâ”€â”€ Data/ # (To store input data files)
â”‚ â””â”€â”€ .gitkeep
â”œâ”€â”€ Model/ # (To store saved model checkpoints)
â”‚ â””â”€â”€ .gitkeep



---

## ğŸš€ Google Colab Support

Both notebooks are optimized for use in [Google Colab](https://colab.research.google.com/), enabling faster training through GPU acceleration.

> âš ï¸ A Google account is required to run Colab notebooks.  
> See the notebooks for setup instructions and privacy considerations.

---

## ğŸ§ª Sample Generation Output

From the trained model:

> Deep Thought, after millions of years,  
> With the ultimate answer appears,  
> &nbsp;&nbsp;&nbsp;&nbsp;Which is just 42.  
> &nbsp;&nbsp;&nbsp;&nbsp;This is certainly true,  
> Though it sounds a bit strange to the ears.

> **Note**: The generated text structure resembles limericks but lacks semantic consistency and rhyme â€” highlighting the potential of LLMs over traditional RNNs for such tasks.

---

## ğŸ› ï¸ Technologies Used

- Python 3.x  
- PyTorch  
- Google Colab  
- Character-level RNNs  
- Text sampling with temperature control


